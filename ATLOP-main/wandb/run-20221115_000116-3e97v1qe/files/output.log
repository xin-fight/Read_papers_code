









Example: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3053/3053 [00:19<00:00, 154.48it/s]
# of documents 3053.
# of positive examples 35615.
# of negative examples 1163035.


Example:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 865/998 [00:05<00:00, 171.70it/s]
# of documents 998.
# of positive examples 11470.
Example: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [00:06<00:00, 152.05it/s]



Example:  95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 953/1000 [00:06<00:00, 53.72it/s]
# of documents 1000.
# of positive examples 0.

Example: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:06<00:00, 145.51it/s]
Total steps: 45780
Warmup steps: 2746
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
C:\Users\pc\anaconda3\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
